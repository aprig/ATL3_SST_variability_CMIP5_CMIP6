{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author : Arthur Prigent\n",
    "# Email : aprigent@geomar.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_librairies import *\n",
    "import xscale.signal.fitting as xsf\n",
    "dir_hist_sst = '/Volumes/Arthur_disk2/Data/CMIP6/Omon/historical/tos/atl3/'\n",
    "dir_hist_uas = '/Volumes/Arthur_disk2/Data/CMIP6/Amon/historical/uas/atl4/'\n",
    "\n",
    "dir_ssp585_sst = '/Volumes/Arthur_disk2/Data/CMIP6/Omon/ssp585/tos/atl3/'\n",
    "dir_ssp126_sst = '/Volumes/Arthur_disk2/Data/CMIP6/Omon/ssp126/tos/atl3/'\n",
    "dir_ssp245_sst = '/Volumes/Arthur_disk2/Data/CMIP6/Omon/ssp245/tos/atl3/'\n",
    "dir_ssp370_sst = '/Volumes/Arthur_disk2/Data/CMIP6/Omon/ssp370/tos/atl3/'\n",
    "\n",
    "dir_ssp585_uas = '/Volumes/Arthur_disk2/Data/CMIP6/Amon/ssp585/uas/atl4/'\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "lon_min = -40\n",
    "lon_max = 5\n",
    "lat_min = -3\n",
    "lat_max = 3\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%d/%m/%Y\")\n",
    "period_str_1 = 1950\n",
    "period_end_1 = 1999\n",
    "\n",
    "period_str_2 = 2050\n",
    "period_end_2 = 2099\n",
    "\n",
    "\n",
    "period_str_3 = 2000\n",
    "period_end_3 = 2014\n",
    "\n",
    "\n",
    "period_str_4 = 1982\n",
    "period_end_4 = 1999\n",
    "\n",
    "period_str_5 = 1950\n",
    "period_end_5 = 2014\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%d/%m/%Y\")\n",
    "def is_jja(month):\n",
    "    return (month >= 6) & (month <= 8)\n",
    "path_fig = '/Users/aprigent/Documents/Thesis_GEOMAR/Projects/weakened_sst_variability_CMIP5/figures/'\n",
    "path_data = '/Users/aprigent/Documents/Thesis_GEOMAR/Projects/weakened_sst_variability_CMIP5/scripts/new_version/to_publish/data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['ACCESS-CM2',\n",
    "         'ACCESS-ESM1-5', 'BCC-CSM2-MR',\n",
    "         'CAMS-CSM1-0', 'CanESM5', 'EC-Earth3', 'EC-Earth3-Veg','GFDL-ESM4',\n",
    "         'INM-CM4-8', 'INM-CM5-0','IPSL-CM6A-LR', 'MIROC6', 'MPI-ESM1-2-HR',\n",
    "         'MPI-ESM1-2-LR', 'MRI-ESM2-0','NESM3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "ACCESS-CM2\n",
      "ACCESS-CM2\n",
      "ACCESS-ESM1-5\n",
      "ACCESS-ESM1-5\n",
      "ACCESS-ESM1-5\n",
      "BCC-CSM2-MR\n",
      "BCC-CSM2-MR\n",
      "BCC-CSM2-MR\n",
      "CAMS-CSM1-0\n",
      "CAMS-CSM1-0\n",
      "CAMS-CSM1-0\n",
      "CanESM5\n",
      "CanESM5\n",
      "CanESM5\n",
      "EC-Earth3\n",
      "EC-Earth3\n",
      "EC-Earth3\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3-Veg\n",
      "GFDL-ESM4\n",
      "GFDL-ESM4\n",
      "No file, pass\n",
      "INM-CM4-8\n",
      "INM-CM4-8\n",
      "INM-CM4-8\n",
      "INM-CM5-0\n",
      "INM-CM5-0\n",
      "INM-CM5-0\n",
      "IPSL-CM6A-LR\n",
      "IPSL-CM6A-LR\n",
      "No file, pass\n",
      "MIROC6\n",
      "MIROC6\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-LR\n",
      "MRI-ESM2-0\n",
      "MRI-ESM2-0\n",
      "No file, pass\n",
      "NESM3\n",
      "NESM3\n",
      "No file, pass\n"
     ]
    }
   ],
   "source": [
    "ssta_std_model_1 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_2 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_3 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_4 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_5 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_6 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_7 = np.ones((len(model),12))*np.nan\n",
    "ssta_std_model_8 = np.ones((len(model),12))*np.nan\n",
    "\n",
    "\n",
    "ssta_model_1 = np.ones((len(model),600))*np.nan\n",
    "ssta_model_2 = np.ones((len(model),600))*np.nan\n",
    "ssta_model_3 = np.ones((len(model),600))*np.nan\n",
    "ssta_model_4 = np.ones((len(model),600))*np.nan\n",
    "ssta_model_5 = np.ones((len(model),600))*np.nan\n",
    "ssta_model_6 = np.ones((len(model),180))*np.nan\n",
    "ssta_model_7 = np.ones((len(model),216))*np.nan\n",
    "ssta_model_8 = np.ones((len(model),780))*np.nan\n",
    "\n",
    "for i in range(len(model)):\n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_sst+'tos_Omon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl3.nc')\n",
    "        sst_tmp_1 = nc_tmp.tos[:]\n",
    "        try:\n",
    "\n",
    "            sst_tmp_1 = sst_tmp_1.sel(time=slice(datetime(period_str_1, 1, 1), datetime(period_end_1, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_1['time'] = sst_tmp_1.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_1 = sst_tmp_1.sel(time=slice(datetime(period_str_1, 1, 1), datetime(period_end_1, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_1 = sst_tmp_1.chunk(chunks=None)\n",
    "        sst_dtd_1 = xsf.detrend(sst_tmp_1[:],dim='time',type='linear')\n",
    "        ssta_1,_ = Atools.ano_norm_t(sst_dtd_1.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_1 = ssta_1.groupby('time.month').std(dim='time')\n",
    "\n",
    "\n",
    "        ssta_model_1[i,:] = ssta_1.values\n",
    "        ssta_std_model_1[i,:] = ssta_std_1.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_1[i,:] = np.nan\n",
    "        ssta_std_model_1[i,:] = np.nan\n",
    "        \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_sst+'tos_Omon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl3.nc')\n",
    "        sst_tmp_6 = nc_tmp.tos[:]\n",
    "        try:\n",
    "\n",
    "            sst_tmp_6 = sst_tmp_6.sel(time=slice(datetime(period_str_3, 1, 1), datetime(period_end_3, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_6['time'] = sst_tmp_6.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_6 = sst_tmp_6.sel(time=slice(datetime(period_str_3, 1, 1), datetime(period_end_3, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_6 = sst_tmp_6.chunk(chunks=None)\n",
    "        sst_dtd_6 = xsf.detrend(sst_tmp_6[:],dim='time',type='linear')\n",
    "        ssta_6,_ = Atools.ano_norm_t(sst_dtd_6.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_6 = ssta_6.groupby('time.month').std(dim='time')\n",
    "\n",
    "\n",
    "        ssta_model_6[i,:] = ssta_6.values\n",
    "        ssta_std_model_6[i,:] = ssta_std_6.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_6[i,:] = np.nan\n",
    "        ssta_std_model_6[i,:] = np.nan\n",
    "        \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_sst+'tos_Omon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl3.nc')\n",
    "        sst_tmp_7 = nc_tmp.tos[:]\n",
    "        try:\n",
    "\n",
    "            sst_tmp_7 = sst_tmp_7.sel(time=slice(datetime(period_str_4, 1, 1), datetime(period_end_4, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_7['time'] = sst_tmp_7.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_7 = sst_tmp_7.sel(time=slice(datetime(period_str_4, 1, 1), datetime(period_end_4, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_7 = sst_tmp_7.chunk(chunks=None)\n",
    "        sst_dtd_7 = xsf.detrend(sst_tmp_7[:],dim='time',type='linear')\n",
    "        ssta_7,_ = Atools.ano_norm_t(sst_dtd_7.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_7 = ssta_7.groupby('time.month').std(dim='time')\n",
    "\n",
    "\n",
    "        ssta_model_7[i,:] = ssta_7.values\n",
    "        ssta_std_model_7[i,:] = ssta_std_7.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_7[i,:] = np.nan\n",
    "        ssta_std_model_7[i,:] = np.nan\n",
    "        \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_sst+'tos_Omon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl3.nc')\n",
    "        sst_tmp_8 = nc_tmp.tos[:]\n",
    "        try:\n",
    "\n",
    "            sst_tmp_8 = sst_tmp_8.sel(time=slice(datetime(period_str_5, 1, 1), datetime(period_end_5, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_8['time'] = sst_tmp_8.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_8 = sst_tmp_8.sel(time=slice(datetime(period_str_5, 1, 1), datetime(period_end_5, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_8 = sst_tmp_8.chunk(chunks=None)\n",
    "        sst_dtd_8 = xsf.detrend(sst_tmp_8[:],dim='time',type='linear')\n",
    "        ssta_8,_ = Atools.ano_norm_t(sst_dtd_8.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_8 = ssta_8.groupby('time.month').std(dim='time')\n",
    "\n",
    "\n",
    "        ssta_model_8[i,:] = ssta_8.values\n",
    "        ssta_std_model_8[i,:] = ssta_std_8.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_8[i,:] = np.nan\n",
    "        ssta_std_model_8[i,:] = np.nan        \n",
    "    ## SSP 585 ## \n",
    "    \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_ssp585_sst+'tos_Omon_'+model[i]+'_ssp585_r1i1p1f1_201501-209912_1deg_atl3.nc')\n",
    "        sst_tmp_2 = nc_tmp.tos[:]\n",
    "\n",
    "        try:\n",
    "\n",
    "            sst_tmp_2 = sst_tmp_2.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_2['time'] = sst_tmp_2.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_2 = sst_tmp_2.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_2 = sst_tmp_2.chunk(chunks=None)\n",
    "        sst_dtd_2 = xsf.detrend(sst_tmp_2[:],dim='time',type='linear')\n",
    "        ssta_2,_ = Atools.ano_norm_t(sst_dtd_2.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_2 = ssta_2.groupby('time.month').std(dim='time')\n",
    "\n",
    "        ssta_std_model_2[i,:] = ssta_std_2.values\n",
    "        ssta_model_2[i,:] = ssta_2.values\n",
    "\n",
    "        print(model[i])\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_std_model_2[i,:] = np.nan\n",
    "        ssta_model_2[i,:] = np.nan\n",
    "    \n",
    "    ## ssp126 ## \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_ssp126_sst+'tos_Omon_'+model[i]+'_ssp126_r1i1p1f1_201501-209912_1deg_atl3.nc')\n",
    "        sst_tmp_3 = nc_tmp.tos[:]\n",
    "\n",
    "        try:\n",
    "\n",
    "            sst_tmp_3 = sst_tmp_3.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_3['time'] = sst_tmp_3.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_3 = sst_tmp_3.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_3 = sst_tmp_3.chunk(chunks=None)\n",
    "        sst_dtd_3 = xsf.detrend(sst_tmp_3[:],dim='time',type='linear')\n",
    "        ssta_3,_ = Atools.ano_norm_t(sst_dtd_3.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_3 = ssta_3.groupby('time.month').std(dim='time')\n",
    "\n",
    "        ssta_model_3[i,:] = ssta_3.values\n",
    "        ssta_std_model_3[i,:] = ssta_std_3.values\n",
    "\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_3[i,:] = np.nan\n",
    "        ssta_std_model_3[i,:] = np.nan\n",
    "    \n",
    "    ## ssp245 ## \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_ssp245_sst+'tos_Omon_'+model[i]+'_ssp245_r1i1p1f1_201501-209912_1deg_atl3.nc')\n",
    "        sst_tmp_4 = nc_tmp.tos[:]\n",
    "    \n",
    "        try:\n",
    "\n",
    "            sst_tmp_4 = sst_tmp_4.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_4['time'] = sst_tmp_4.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_4 = sst_tmp_4.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_4 = sst_tmp_4.chunk(chunks=None)\n",
    "        sst_dtd_4 = xsf.detrend(sst_tmp_4[:],dim='time',type='linear')\n",
    "        ssta_4,_ = Atools.ano_norm_t(sst_dtd_4.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_4 = ssta_4.groupby('time.month').std(dim='time')\n",
    "\n",
    "        ssta_model_4[i,:] = ssta_4.values\n",
    "        ssta_std_model_4[i,:] = ssta_std_4.values\n",
    "    \n",
    "        print(model[i])\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_4[i,:] = np.nan\n",
    "        ssta_std_model_4[i,:] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ssp370 ## \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_ssp370_sst+'tos_Omon_'+model[i]+'_ssp370_r1i1p1f1_201501-209912_1deg_atl3.nc')\n",
    "        sst_tmp_5 = nc_tmp.tos[:]\n",
    "\n",
    "        try:\n",
    "\n",
    "            sst_tmp_5 = sst_tmp_5.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            sst_tmp_5['time'] = sst_tmp_5.indexes['time'].to_datetimeindex()\n",
    "            sst_tmp_5 = sst_tmp_5.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "\n",
    "\n",
    "        sst_tmp_5 = sst_tmp_5.chunk(chunks=None)\n",
    "        sst_dtd_5 = xsf.detrend(sst_tmp_5[:],dim='time',type='linear')\n",
    "        ssta_5,_ = Atools.ano_norm_t(sst_dtd_5.mean(dim='lon').mean(dim='lat').load())\n",
    "        ssta_std_5 = ssta_5.groupby('time.month').std(dim='time')\n",
    "\n",
    "        ssta_model_5[i,:] = ssta_5.values\n",
    "        ssta_std_model_5[i,:] = ssta_std_5.values\n",
    "\n",
    "        print(model[i])\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        ssta_model_5[i,:] = np.nan\n",
    "        ssta_std_model_5[i,:] = np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uwind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "ACCESS-CM2\n",
      "ACCESS-CM2\n",
      "ACCESS-ESM1-5\n",
      "ACCESS-ESM1-5\n",
      "ACCESS-ESM1-5\n",
      "BCC-CSM2-MR\n",
      "BCC-CSM2-MR\n",
      "BCC-CSM2-MR\n",
      "CAMS-CSM1-0\n",
      "CAMS-CSM1-0\n",
      "CAMS-CSM1-0\n",
      "CanESM5\n",
      "CanESM5\n",
      "CanESM5\n",
      "EC-Earth3\n",
      "EC-Earth3\n",
      "EC-Earth3\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3-Veg\n",
      "EC-Earth3-Veg\n",
      "GFDL-ESM4\n",
      "GFDL-ESM4\n",
      "GFDL-ESM4\n",
      "INM-CM4-8\n",
      "INM-CM4-8\n",
      "INM-CM4-8\n",
      "INM-CM5-0\n",
      "INM-CM5-0\n",
      "INM-CM5-0\n",
      "IPSL-CM6A-LR\n",
      "IPSL-CM6A-LR\n",
      "IPSL-CM6A-LR\n",
      "MIROC6\n",
      "MIROC6\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-LR\n",
      "MPI-ESM1-2-LR\n",
      "MRI-ESM2-0\n",
      "MRI-ESM2-0\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NESM3\n",
      "NESM3\n"
     ]
    }
   ],
   "source": [
    "uasa_std_model_1 = np.ones((len(model),12))*np.nan\n",
    "uasa_std_model_2 = np.ones((len(model),12))*np.nan\n",
    "uasa_std_model_6 = np.ones((len(model),12))*np.nan\n",
    "uasa_std_model_7 = np.ones((len(model),12))*np.nan\n",
    "\n",
    "uasa_model_1 = np.ones((len(model),600))*np.nan\n",
    "uasa_model_2 = np.ones((len(model),600))*np.nan\n",
    "uasa_model_6 = np.ones((len(model),180))*np.nan\n",
    "uasa_model_7 = np.ones((len(model),216))*np.nan\n",
    "\n",
    "\n",
    "model_id_uas = []\n",
    "for i in range(len(model)):\n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_uas+'uas_Amon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl4.nc')\n",
    "        uas_tmp_1 = nc_tmp.uas[:]\n",
    "        print(model[i])\n",
    "\n",
    "        try:\n",
    "\n",
    "            uas_tmp_1 = uas_tmp_1.sel(time=slice(datetime(period_str_1, 1, 1), datetime(period_end_1, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            uas_tmp_1['time'] = uas_tmp_1.indexes['time'].to_datetimeindex()\n",
    "            uas_tmp_1 = uas_tmp_1.sel(time=slice(datetime(period_str_1, 1, 1), datetime(period_end_1, 12, 31)))\n",
    "\n",
    "\n",
    "\n",
    "        uas_tmp_1 = uas_tmp_1.chunk(chunks=None)\n",
    "        uas_dtd_1 = xsf.detrend(uas_tmp_1[:],dim='time',type='linear')\n",
    "        uasa_1,_ = Atools.ano_norm_t(uas_dtd_1.mean(dim='lon').mean(dim='lat').load())\n",
    "        uasa_std_1 = uasa_1.groupby('time.month').std(dim='time')\n",
    "\n",
    "        uasa_std_model_1[i,:] = uasa_std_1.values\n",
    "        uasa_model_1[i,:] = uasa_1.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        uasa_model_1[i,:] = np.nan\n",
    "        uasa_std_model_1[i,:] = np.nan\n",
    "        \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_uas+'uas_Amon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl4.nc')\n",
    "        uas_tmp_6 = nc_tmp.uas[:]\n",
    "        print(model[i])\n",
    "\n",
    "        try:\n",
    "\n",
    "            uas_tmp_6 = uas_tmp_6.sel(time=slice(datetime(period_str_3, 1, 1), datetime(period_end_3, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            uas_tmp_6['time'] = uas_tmp_6.indexes['time'].to_datetimeindex()\n",
    "            uas_tmp_6 = uas_tmp_6.sel(time=slice(datetime(period_str_3, 1, 1), datetime(period_end_3, 12, 31)))\n",
    "\n",
    "\n",
    "\n",
    "        uas_tmp_6 = uas_tmp_6.chunk(chunks=None)\n",
    "        uas_dtd_6 = xsf.detrend(uas_tmp_6[:],dim='time',type='linear')\n",
    "        uasa_6,_ = Atools.ano_norm_t(uas_dtd_6.mean(dim='lon').mean(dim='lat').load())\n",
    "        uasa_std_6 = uasa_6.groupby('time.month').std(dim='time')\n",
    "\n",
    "        uasa_std_model_6[i,:] = uasa_std_6.values\n",
    "        uasa_model_6[i,:] = uasa_6.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        uasa_model_6[i,:] = np.nan\n",
    "        uasa_std_model_6[i,:] = np.nan\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_hist_uas+'uas_Amon_'+model[i]+'_historical_r1i1p1f1_187001-201412_1deg_atl4.nc')\n",
    "        uas_tmp_7 = nc_tmp.uas[:]\n",
    "        print(model[i])\n",
    "\n",
    "        try:\n",
    "\n",
    "            uas_tmp_7 = uas_tmp_7.sel(time=slice(datetime(period_str_4, 1, 1), datetime(period_end_4, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            uas_tmp_7['time'] = uas_tmp_7.indexes['time'].to_datetimeindex()\n",
    "            uas_tmp_7 = uas_tmp_7.sel(time=slice(datetime(period_str_4, 1, 1), datetime(period_end_4, 12, 31)))\n",
    "\n",
    "\n",
    "\n",
    "        uas_tmp_7 = uas_tmp_7.chunk(chunks=None)\n",
    "        uas_dtd_7 = xsf.detrend(uas_tmp_7[:],dim='time',type='linear')\n",
    "        uasa_7,_ = Atools.ano_norm_t(uas_dtd_7.mean(dim='lon').mean(dim='lat').load())\n",
    "        uasa_std_7 = uasa_7.groupby('time.month').std(dim='time')\n",
    "\n",
    "        uasa_std_model_7[i,:] = uasa_std_7.values\n",
    "        uasa_model_7[i,:] = uasa_7.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        uasa_model_7[i,:] = np.nan\n",
    "        uasa_std_model_7[i,:] = np.nan\n",
    "\n",
    "    ############################################################\n",
    "    \n",
    "    try:\n",
    "        nc_tmp = xr.open_dataset(dir_ssp585_uas+'uas_Amon_'+model[i]+'_ssp585_r1i1p1f1_201501-209912_1deg_atl4.nc')\n",
    "        uas_tmp_2 = nc_tmp.uas[:]\n",
    "        try:\n",
    "\n",
    "            uas_tmp_2 = uas_tmp_2.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "        except TypeError:\n",
    "\n",
    "            uas_tmp_2['time'] = uas_tmp_2.indexes['time'].to_datetimeindex()\n",
    "            uas_tmp_2 = uas_tmp_2.sel(time=slice(datetime(period_str_2, 1, 1), datetime(period_end_2, 12, 31)))\n",
    "\n",
    "\n",
    "\n",
    "        uas_tmp_2 = uas_tmp_2.chunk(chunks=None)\n",
    "        uas_dtd_2 = xsf.detrend(uas_tmp_2[:],dim='time',type='linear')\n",
    "\n",
    "        uasa_2,_ = Atools.ano_norm_t(uas_dtd_2.mean(dim='lon').mean(dim='lat').load())\n",
    "        uasa_std_2 = uasa_2.groupby('time.month').std(dim='time')\n",
    "\n",
    "\n",
    "        uasa_std_model_2[i,:] = uasa_std_2.values\n",
    "        uasa_model_2[i,:] = uasa_2.values\n",
    "    except FileNotFoundError:\n",
    "        print('No file, pass')\n",
    "        uasa_model_2[i,:] = np.nan\n",
    "        uasa_std_model_2[i,:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = np.arange(1,13,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#monthly_ssta_std_model_1  = xr.Dataset({'ssta_std': (['model','month'],ssta_std_model_1)}\n",
    "#                           ,coords={'model': model,\n",
    "#                                    'month': np.array(month)}\n",
    "#\n",
    "#                           ,attrs={'standard_name': 'std_ssta',\n",
    "#                                    'long_name': 'Standard deviation of SSTa',\n",
    "#                                    'units': 'K',\n",
    "#                                    'model': 'CMIP6',\n",
    "#                                    'Scenario': 'Historical',\n",
    "#                                    'Creation_date':date_time,   \n",
    "#                                    'author': 'Arthur Prigent'})\n",
    "#\n",
    "#monthly_ssta_std_model_2  = xr.Dataset({'ssta_std': (['model','month'],ssta_std_model_2)}\n",
    "#                           ,coords={'model': model,\n",
    "#                                    'month': np.array(month)}\n",
    "#\n",
    "#                           ,attrs={'standard_name': 'std_ssta',\n",
    "#                                    'long_name': 'Standard deviation of SSTa',\n",
    "#                                    'units': 'K',\n",
    "#                                    'model': 'CMIP6',\n",
    "#                                    'Scenario': 'SSP585',\n",
    "#                                    'Creation_date':date_time,   \n",
    "#                                    'author': 'Arthur Prigent'})\n",
    "#\n",
    "#monthly_ssta_std_model_3  = xr.Dataset({'ssta_std': (['model','month'],ssta_std_model_3)}\n",
    "#                           ,coords={'model': model,\n",
    "#                                    'month': np.array(month)}\n",
    "#\n",
    "#                           ,attrs={'standard_name': 'std_ssta',\n",
    "#                                    'long_name': 'Standard deviation of SSTa',\n",
    "#                                    'units': 'K',\n",
    "#                                    'model': 'CMIP6',\n",
    "#                                    'Scenario': 'SSP126',\n",
    "#                                    'Creation_date':date_time,   \n",
    "#                                    'author': 'Arthur Prigent'})\n",
    "#\n",
    "#monthly_ssta_std_model_4  = xr.Dataset({'ssta_std': (['model','month'],ssta_std_model_4)}\n",
    "#                           ,coords={'model': model,\n",
    "#                                    'month': np.array(month)}\n",
    "#\n",
    "#                           ,attrs={'standard_name': 'std_ssta',\n",
    "#                                    'long_name': 'Standard deviation of SSTa',\n",
    "#                                    'units': 'K',\n",
    "#                                    'model': 'CMIP6',\n",
    "#                                    'Scenario': 'SSP245',\n",
    "#                                    'Creation_date':date_time,   \n",
    "#                                    'author': 'Arthur Prigent'})\n",
    "#\n",
    "#monthly_ssta_std_model_5  = xr.Dataset({'ssta_std': (['model','month'],ssta_std_model_5)}\n",
    "#                           ,coords={'model': model,\n",
    "#                                    'month': np.array(month)}\n",
    "#\n",
    "#                           ,attrs={'standard_name': 'std_ssta',\n",
    "#                                    'long_name': 'Standard deviation of SSTa',\n",
    "#                                    'units': 'K',\n",
    "#                                    'model': 'CMIP6',\n",
    "#                                    'Scenario': 'SSP370',\n",
    "#                                    'Creation_date':date_time,   \n",
    "#                                    'author': 'Arthur Prigent'})\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "monthly_ssta_model_1  = xr.Dataset({'ssta': (['model','time'],ssta_model_1)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_1.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'Historical',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "monthly_ssta_model_2  = xr.Dataset({'ssta': (['model','time'],ssta_model_2)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_2.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'RCP85',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_ssta_model_3  = xr.Dataset({'ssta': (['model','time'],ssta_model_3)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_3.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'RCP45',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_ssta_model_4  = xr.Dataset({'ssta': (['model','time'],ssta_model_4)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_4.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'SSP245',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "monthly_ssta_model_5  = xr.Dataset({'ssta': (['model','time'],ssta_model_5)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_5.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'SSP370',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_ssta_model_6  = xr.Dataset({'ssta': (['model','time'],ssta_model_6)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_6.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'Hist',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_ssta_model_7  = xr.Dataset({'ssta': (['model','time'],ssta_model_7)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_7.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'Hist',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_ssta_model_8  = xr.Dataset({'ssta': (['model','time'],ssta_model_8)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(ssta_8.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_ssta',\n",
    "                                    'long_name': 'SST anomalies',\n",
    "                                    'units': 'K',\n",
    "                                    'model': 'CMIP5',\n",
    "                                    'Scenario': 'Hist',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#monthly_ssta_std_model_1.to_netcdf(path_data+'std_ssta_hist_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_std_model_2.to_netcdf(path_data+'std_ssta_ssp585_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_std_model_3.to_netcdf(path_data+'std_ssta_ssp126_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_std_model_4.to_netcdf(path_data+'std_ssta_ssp245_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_std_model_5.to_netcdf(path_data+'std_ssta_ssp370_monthly_CMIP6.nc',mode='w')\n",
    "#\n",
    "monthly_ssta_model_1.to_netcdf(path_data+'ssta_hist_monthly_CMIP6.nc',mode='w')\n",
    "monthly_ssta_model_2.to_netcdf(path_data+'ssta_ssp585_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_model_3.to_netcdf(path_data+'ssta_ssp126_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_model_4.to_netcdf(path_data+'ssta_ssp245_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_ssta_model_5.to_netcdf(path_data+'ssta_ssp370_monthly_CMIP6.nc',mode='w')\n",
    "monthly_ssta_model_6.to_netcdf(path_data+'ssta_hist_monthly_CMIP6_2000_2014.nc',mode='w')\n",
    "monthly_ssta_model_7.to_netcdf(path_data+'ssta_hist_monthly_CMIP6_1982_1999.nc',mode='w')\n",
    "\n",
    "#monthly_ssta_model_8.to_netcdf(path_data+'ssta_hist_monthly_CMIP6_1950_2014.nc',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_uasa_std_model_1  = xr.Dataset({'uasa_std': (['model','month'],uasa_std_model_1)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'month': np.array(month)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'Historical',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "monthly_uasa_std_model_2  = xr.Dataset({'uasa_std': (['model','month'],uasa_std_model_2)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'month': np.array(month)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'RCP8.5',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "monthly_uasa_model_1  = xr.Dataset({'uasa': (['model','time'],uasa_model_1)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(uasa_1.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'Historical',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "monthly_uasa_model_2  = xr.Dataset({'uasa': (['model','time'],uasa_model_2)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(uasa_2.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'RCP8.5',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "monthly_uasa_model_6  = xr.Dataset({'uasa': (['model','time'],uasa_model_6)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(uasa_6.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'RCP8.5',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})\n",
    "\n",
    "\n",
    "\n",
    "monthly_uasa_model_7  = xr.Dataset({'uasa': (['model','time'],uasa_model_7)}\n",
    "                           ,coords={'model': model,\n",
    "                                    'time': np.array(uasa_7.time.values)}\n",
    "\n",
    "                           ,attrs={'standard_name': 'std_uasa',\n",
    "                                    'long_name': 'Standard deviation of Zonal wind speed anomalies',\n",
    "                                    'units': 'm/s',\n",
    "                                    'model': 'CMIP6',\n",
    "                                    'Scenario': 'RCP8.5',\n",
    "                                    'Creation_date':date_time,   \n",
    "                                    'author': 'Arthur Prigent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly_uasa_std_model_1.to_netcdf(path_data+\n",
    "#    'std_uasa_hist_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_uasa_std_model_2.to_netcdf(path_data+\n",
    "#    'std_uasa_ssp5_monthly_CMIP6.nc',mode='w')\n",
    "\n",
    "#monthly_uasa_model_1.to_netcdf(path_data+\n",
    "#    'uasa_hist_monthly_CMIP6.nc',mode='w')\n",
    "#monthly_uasa_model_2.to_netcdf(path_data+\n",
    "#    'uasa_ssp5_monthly_CMIP6.nc',mode='w')\n",
    "#\n",
    "\n",
    "\n",
    "monthly_uasa_model_6.to_netcdf(path_data+\n",
    "    'uasa_hist_monthly_CMIP6_2000_2014.nc',mode='w')\n",
    "\n",
    "monthly_uasa_model_7.to_netcdf(path_data+\n",
    "    'uasa_hist_monthly_CMIP6_1982_1999.nc',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
